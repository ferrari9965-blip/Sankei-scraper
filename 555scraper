import requests
from bs4 import BeautifulSoup
import csv
import time

BASE_URL = "http://www.sankei-555.com/search/list.php"

headers = {
    "User-Agent": "Mozilla/5.0"
}

offset = 0
finished = False

with open("catalog.csv", "w", newline="", encoding="utf-8") as f:
    writer = None

    while not finished:
        print(f"Scraping offset {offset}")

        params = {"1": "1", "offset": offset}
        r = requests.get(BASE_URL, params=params, headers=headers)
        soup = BeautifulSoup(r.text, "html.parser")

        table = soup.find("table")
        rows = table.find_all("tr")

        if len(rows) <= 1:
            finished = True
            break

        if writer is None:
            headers_row = [th.get_text(strip=True) for th in rows[0].find_all("th")]
            writer = csv.writer(f)
            writer.writerow(headers_row)

        count = 0
        for tr in rows[1:]:
            cols = [td.get_text(strip=True) for td in tr.find_all("td")]
            if cols:
                writer.writerow(cols)
                count += 1

        offset += count
        time.sleep(1)

print("Done! File saved as catalog.csv")
